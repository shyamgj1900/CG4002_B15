{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6c21cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import DefaultIP\n",
    "from pynq import allocate\n",
    "from pynq import MMIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler #new\n",
    "\n",
    "\n",
    "import time\n",
    "overlay = Overlay(\"./hardware_ai/cg4002/design_1_wrapper.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a525ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy --upgrade --ignore-installed\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0f0fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c4ec43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_IP_BASE_ADDRESS = 0x80000000\n",
    "ADDRESS_RANGE = 0x10000\n",
    "ADDRESS_OFFSET = 0x0\n",
    "\n",
    "mmio = MMIO(NN_IP_BASE_ADDRESS, ADDRESS_RANGE)\n",
    "ap_start = 0x1\n",
    "ap_auto_reset = 0x80\n",
    "mmio.write(ADDRESS_OFFSET, ap_start|ap_auto_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06cccac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "def compute_variance(data):\n",
    "    return np.var(data)\n",
    "\n",
    "def compute_median_absolute_deviation(data):\n",
    "    return stats.median_absolute_deviation(data)\n",
    "\n",
    "def compute_root_mean_square(data):\n",
    "    def compose(*fs):\n",
    "        def wrapped(x):\n",
    "            for f in fs[::-1]:\n",
    "                x = f(x)\n",
    "            return x\n",
    "        return wrapped\n",
    "    rms = compose(np.sqrt, np.mean, np.square)\n",
    "    return rms(data)\n",
    "\n",
    "def compute_interquartile_range(data):\n",
    "    return stats.iqr(data)\n",
    "\n",
    "def compute_percentile_75(data):\n",
    "    return np.percentile(data, 75)\n",
    "\n",
    "def compute_kurtosis(data):\n",
    "    return stats.kurtosis(data)\n",
    "\n",
    "def compute_min_max(data):\n",
    "    return np.max(data) - np.min(data)\n",
    "\n",
    "def compute_signal_magnitude_area(data):\n",
    "    return np.sum(data) / len(data)\n",
    "\n",
    "def compute_zero_crossing_rate(data):\n",
    "    return ((data[:-1] * data[1:]) < 0).sum()\n",
    "\n",
    "def compute_spectral_centroid(data):\n",
    "    spectrum = np.abs(np.fft.rfft(data))\n",
    "    normalized_spectrum = spectrum / np.sum(spectrum)  \n",
    "    normalized_frequencies = np.linspace(0, 1, len(spectrum))\n",
    "    spectral_centroid = np.sum(normalized_frequencies * normalized_spectrum)\n",
    "    return spectral_centroid\n",
    "\n",
    "def compute_spectral_entropy(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return stats.entropy(power_density)\n",
    "\n",
    "def compute_spectral_energy(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return np.sum(np.square(power_density))\n",
    "\n",
    "def compute_principle_frequency(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return freqs[np.argmax(np.square(power_density))]\n",
    "\n",
    "def extract_raw_data_features_per_row(f_n):\n",
    "    f1_mean = compute_mean(f_n)\n",
    "    f1_var = compute_variance(f_n)\n",
    "    f1_mad = compute_median_absolute_deviation(f_n)\n",
    "    f1_rms = compute_root_mean_square(f_n)\n",
    "    f1_iqr = compute_interquartile_range(f_n)\n",
    "    f1_per75 = compute_percentile_75(f_n)\n",
    "    f1_kurtosis = compute_kurtosis(f_n)\n",
    "    f1_min_max = compute_min_max(f_n)\n",
    "    f1_sma = compute_signal_magnitude_area(f_n)\n",
    "    f1_zcr = compute_zero_crossing_rate(f_n)\n",
    "    f1_sc = compute_spectral_centroid(f_n)\n",
    "    f1_entropy = compute_spectral_entropy(f_n)\n",
    "    f1_energy = compute_spectral_energy(f_n)\n",
    "    f1_pfreq = compute_principle_frequency(f_n)\n",
    "    return f1_mean, f1_var, f1_mad, f1_rms, f1_iqr, f1_per75, f1_kurtosis, f1_min_max, f1_sma, f1_zcr, f1_sc, f1_entropy, f1_energy, f1_pfreq\n",
    "\n",
    "def extract_raw_data_features(X):\n",
    "    new_features = []\n",
    "#     rows = X.shape[0]\n",
    "#     cols = X.shape[1]\n",
    "#     for row in range(rows):\n",
    "#         features = []\n",
    "#         for col in range(cols):\n",
    "#             f_n = np.array(X[row][col])\n",
    "#             feature = extract_raw_data_features_per_row(f_n)\n",
    "#             features.append(feature)\n",
    "#         new_features.append(features)\n",
    "    for col in [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]:\n",
    "        features = []\n",
    "        f_n = np.array(X[col])\n",
    "        feature = extract_raw_data_features_per_row(f_n)\n",
    "#         features.append(feature)\n",
    "        new_features.append(feature)\n",
    "#     new\n",
    "#     return pd.DataFrame(data=np.array(new_features), columns=[\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"] )\n",
    "    return new_features\n",
    "\n",
    "# cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]\n",
    "# final_data = extract_raw_data_features(np.array(pdata[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbf4cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featureslist(final_data):\n",
    "#     new_data = []\n",
    "#     for row in range(0,np.array(final_data).shape[0]):\n",
    "#         row_features = []\n",
    "#         for col in range(0,np.array(final_data).shape[1]):\n",
    "#             feature_list = np.array(final_data)[row][col]\n",
    "#             for feature in feature_list:\n",
    "#                 row_features.append(feature)\n",
    "#         new_data.append(row_features)\n",
    "#         print(\"Row: \" + str(row) + \"done\")\n",
    "\n",
    "#     feature_name_list = [\"_mean\", \"_var\", \"_mad\", \"_rms\", \"_iqr\", \"_per75\", \"_kurtosis\", \"_min_max\", \"_sma\", \"_zcr\", \"_sc\", \"_entropy\", \"_energy\", \"_pfreq\"]\n",
    "#     cols = []\n",
    "#     for things in [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]:\n",
    "#         for feature in feature_name_list:\n",
    "#             cols.append(things+feature)\n",
    "\n",
    "#     data = pd.DataFrame(data=np.array(new_data), columns=cols)\n",
    "#     data = data.dropna()\n",
    "    new_data = []\n",
    "    for row in range(np.array(final_data).shape[0]):\n",
    "        for col in range(np.array(final_data).shape[1]):\n",
    "            new_data.append(final_data[row][col])\n",
    "    return new_data\n",
    "#     return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7458d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(data):\n",
    "    combined_raw = []\n",
    "    new_data = []\n",
    "#     new_data = pd.DataFrame(columns=['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    for col in range(6):\n",
    "        for row in range(len(data)):\n",
    "            combined_raw.append(data[row][col])\n",
    "        new_data.append(combined_raw)\n",
    "        combined_raw = []\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3dd3f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "27054f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-86.135, 2582.770705, 40.764086999999996, 100.0100441455757, 78.46000000000001, -52.7275, -1.1948701209865802, 146.78, -86.135, 0.0, 0.20681086487538158, 1.427999385552897, 226163090.69759995, 0.1, 43.071000000000005, 3605.7032090000007, 11.93493, 73.89732234661822, 93.175, 95.6125, -1.138280652568172, 154.69, 43.071000000000005, 2.0, 0.28576026812014466, 0.9136870118950315, 275317901.93160003, 0.1, -43.899, 5649.424569, 4.966709999999996, 87.04336143555119, 13.165, -47.645, 3.0931994465751567, 294.75, -43.899, 1.0, 0.4527810917881688, 1.499249028754572, 27243953.131914373, 0.1, -2711.3, 33751011.010000005, 2679.0582, 6411.0965286758865, 5860.75, 688.25, -0.48271303043482616, 18345.0, -2711.3, 3.0, 0.3326155634295996, 1.1446630625406318, 4.94697987869004e+16, 0.1, -2704.4, 39706443.239999995, 1608.6209999999999, 6857.1293264747455, 8173.0, 241.25, -0.809410384051203, 21505.0, -2704.4, 2.0, 0.27388573789686504, 1.3196692453762005, 6.366557915460763e+16, 0.1, 3673.3, 59095920.40999999, 1358.8029, 8519.920967943306, 1095.0, 6487.75, 1.0535633309910413, 28215.0, 3673.3, 1.0, 0.36831800913345725, 1.3604956501439391, 2.7700872922620956e+16, 0.1]]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-b47bf291d83e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#     return 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#return lower case string // if not an action, return none.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-b47bf291d83e>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(raw_data)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mfinal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m#generate prediction from model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/pynq-venv/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/pynq-venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#define a function which accepts raw data parameter.\n",
    "#raw data would be a queue the form 600 * ['W',acc_x,acc_y,acc_z,gyr_x,gyr_y,gyr_z]\n",
    "# raw_data = []\n",
    "# pkt1 = ('W',0.2,0.2,0.3,0.4,0.5,0.6)\n",
    "# pkt2 = ('W',0.1,0.1,0.1,1.1,1.2,0.1)\n",
    "# pkt3 = ('W',1.1,1.2,1.3,0.1,100000,1.6)\n",
    "# raw_data.append(pkt1)\n",
    "# raw_data.append(pkt2)\n",
    "# raw_data.append(pkt3)\n",
    "raw_data = [['W', -70.38, 3.27, -48.11, -121.0, -141.0, 6394.0],\n",
    "            ['W', -71.03, 2.55, -48.44, -210.0, 59.0, 6410.0],\n",
    "            ['W', -70.43, 2.68, -48.73, -327.0, 302.0, 6501.0],\n",
    "            ['W', -60.4, 2.4, -47.49, -491.0, 57.0, 6448.0],\n",
    "            ['W', -50.17, -5.85, -46.28, 958.0, 812.0, 5671.0],\n",
    "            ['W', -35.65, -4.3, -52.98, 3807.0, 7830.0, 7993.0],\n",
    "            ['W', -22.88, 30.97, -63.42, -6733.0, -1358.0, 13112.0],\n",
    "            ['W', -159.51, 117.16, -116.31, -14538.0, -10123.0, 5300.0],\n",
    "            ['W', -169.66, 132.99, -130.99, -11577.0, -13675.0, -5993.0],\n",
    "            ['W', -151.24, 148.84, 163.76, 2119.0, -10807.0, -15103.0]]\n",
    "\n",
    "def process(raw_data):\n",
    "    data = pd.DataFrame(columns=['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    for i in range(len(raw_data)):\n",
    "        list_row = [raw_data[i][1],raw_data[i][2],raw_data[i][3],raw_data[i][4],raw_data[i][5],raw_data[i][6]]\n",
    "        data.loc[len(data)] = list_row\n",
    "    final_data = combine_rows(data.values.tolist())\n",
    "    final_data = pd.DataFrame(data=np.array(final_data).T, columns = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"])\n",
    "    final_data = extract_raw_data_features(final_data)\n",
    "    final_data = np.array([create_featureslist(final_data)])\n",
    "#     final_data = np.swapaxes(final_data, 0, 1)\n",
    "#     final_data = list(map(lambda x: x[0], final_data))\n",
    "#     print(len(final_data[0]))\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(np.array(final_data).reshape(1, -1).tolist())\n",
    "#     final_data = scaler.transform(np.array(final_data).reshape(1, -1))\n",
    "#     print(final_data)\n",
    "#     final_data = pd.DataFrame(final_data)\n",
    "#     final_data = final_data[final_data.columns[:84]].astype('float64').to_numpy()\n",
    "#     print(final_data.tolist())\n",
    "    scaler=load('scaler.joblib')\n",
    "#     scaler = StandardScaler()\n",
    "    scaler.transform(final_data.tolist())\n",
    "#     print(final_data.tolist())\n",
    "\n",
    "#     final_data = scaler.transform(final_data.tolist())\n",
    "#     print(final_data.tolist())\n",
    "\n",
    "    model = load_model('./hardware_ai/cg4002/detection.h5')\n",
    "#     model.get_weights()\n",
    "    final_data = np.array([final_data])\n",
    "    #generate prediction from model\n",
    "    output = model.predict(scaler.transform(final_data).tolist()[0])\n",
    "    prediction = output.index(max(output))\n",
    "\n",
    "    if prediction == 0:\n",
    "        return \"reload\"\n",
    "    if prediction == 1:\n",
    "        return \"shield\"\n",
    "    if prediction == 2:\n",
    "        return \"grenade\"\n",
    "    if prediction == 3:\n",
    "        return \"logout\"\n",
    "    if prediction == 4:\n",
    "        return \"\"\n",
    "#     return prediction\n",
    "    \n",
    "#     return output\n",
    "# def process(raw_data):\n",
    "#     print(\"Hello. I have received the raw data.\" + \"This is the first packed.\" + raw_data[0])\n",
    "#     return 1\n",
    "\n",
    "process(raw_data)      \n",
    "    \n",
    "#return lower case string // if not an action, return none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_file(filepath):\n",
    "  dataframe = pd.read_csv(filepath)\n",
    "  return dataframe\n",
    "\n",
    "data = load_file(\"./hardware_ai/cg4002/data.csv\")\n",
    "data.head()\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.columns[:84]].astype('float64').to_numpy()\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8204e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"prediction\"].to_numpy()\n",
    "x = data[data.columns[1:85]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97698873",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1] * 84)\n",
    "y = np.array([0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39670ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = 0\n",
    "#Setting a threshold for onset detection\n",
    "# THRESHOLD = 0.01\n",
    "# threshold_sum = 0\n",
    "dma = overlay.axi_dma_0        \n",
    "# take in 10 datapoints, average out, compare to threshold\n",
    "in_buffer = allocate(shape=x.shape, dtype=np.double)\n",
    "out_buffer = allocate(shape=(1,), dtype=np.double)\n",
    "print(in_buffer)\n",
    "print(out_buffer)\n",
    "for i in range(x.shape[0]):\n",
    "    overlay = Overlay(\"./hardware_ai/cg4002/design_1_wrapper.bit\")\n",
    "    dma = overlay.axi_dma_0        \n",
    "#     inputs = x[n]\n",
    "#     for i in range(84):\n",
    "    in_buffer[i] = x[i];\n",
    "#         threshold_sum += inputs[i];\n",
    "#         print(threshold_sum)\n",
    "# print(in_buffer)\n",
    "# print(out_buffer)\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "# print(\"aaa1\")\n",
    "# print(in_buffer)\n",
    "# print(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "# print(\"aaa2\")\n",
    "dma.recvchannel.wait()\n",
    "# print(\"aaa3\")\n",
    "\n",
    "out_buffer\n",
    "# if y[i] == np.argmax(out_buffer):\n",
    "#     correct_pred += 1;\n",
    "\n",
    "# accuracy = 100 * correct_pred / len(x)\n",
    "# print('Accuracy: {}'. format(accuracy))\n",
    "# print('Process time: ' + str(time.time() - start) + \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17fbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
