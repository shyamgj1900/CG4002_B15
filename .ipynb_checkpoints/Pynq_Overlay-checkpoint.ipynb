{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c21cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/pynq-venv/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/share/pynq-venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: [\"[Errno 2] The file to load file system plugin from does not exist.: '/usr/local/share/pynq-venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so'\"]\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/usr/local/share/pynq-venv/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/share/pynq-venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/usr/local/share/pynq-venv/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: cannot open shared object file: No such file or directory']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import DefaultIP\n",
    "from pynq import allocate\n",
    "from pynq import MMIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import time\n",
    "overlay = Overlay(\"./hardware_ai/cg4002/design_1_wrapper.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db84f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy --upgrade --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4ec43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_IP_BASE_ADDRESS = 0x80000000\n",
    "ADDRESS_RANGE = 0x10000\n",
    "ADDRESS_OFFSET = 0x0\n",
    "\n",
    "mmio = MMIO(NN_IP_BASE_ADDRESS, ADDRESS_RANGE)\n",
    "ap_start = 0x1\n",
    "ap_auto_reset = 0x80\n",
    "mmio.write(ADDRESS_OFFSET, ap_start|ap_auto_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cccac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "def compute_variance(data):\n",
    "    return np.var(data)\n",
    "\n",
    "def compute_median_absolute_deviation(data):\n",
    "    return stats.median_absolute_deviation(data)\n",
    "\n",
    "def compute_root_mean_square(data):\n",
    "    def compose(*fs):\n",
    "        def wrapped(x):\n",
    "            for f in fs[::-1]:\n",
    "                x = f(x)\n",
    "            return x\n",
    "        return wrapped\n",
    "    rms = compose(np.sqrt, np.mean, np.square)\n",
    "    return rms(data)\n",
    "\n",
    "def compute_interquartile_range(data):\n",
    "    return stats.iqr(data)\n",
    "\n",
    "def compute_percentile_75(data):\n",
    "    return np.percentile(data, 75)\n",
    "\n",
    "def compute_kurtosis(data):\n",
    "    return stats.kurtosis(data)\n",
    "\n",
    "def compute_min_max(data):\n",
    "    return np.max(data) - np.min(data)\n",
    "\n",
    "def compute_signal_magnitude_area(data):\n",
    "    return np.sum(data) / len(data)\n",
    "\n",
    "def compute_zero_crossing_rate(data):\n",
    "    return ((data[:-1] * data[1:]) < 0).sum()\n",
    "\n",
    "def compute_spectral_centroid(data):\n",
    "    spectrum = np.abs(np.fft.rfft(data))\n",
    "    normalized_spectrum = spectrum / np.sum(spectrum)  \n",
    "    normalized_frequencies = np.linspace(0, 1, len(spectrum))\n",
    "    spectral_centroid = np.sum(normalized_frequencies * normalized_spectrum)\n",
    "    return spectral_centroid\n",
    "\n",
    "def compute_spectral_entropy(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return stats.entropy(power_density)\n",
    "\n",
    "def compute_spectral_energy(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return np.sum(np.square(power_density))\n",
    "\n",
    "def compute_principle_frequency(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return freqs[np.argmax(np.square(power_density))]\n",
    "\n",
    "def extract_raw_data_features_per_row(f_n):\n",
    "    f1_mean = compute_mean(f_n)\n",
    "    f1_var = compute_variance(f_n)\n",
    "    f1_mad = compute_median_absolute_deviation(f_n)\n",
    "    f1_rms = compute_root_mean_square(f_n)\n",
    "    f1_iqr = compute_interquartile_range(f_n)\n",
    "    f1_per75 = compute_percentile_75(f_n)\n",
    "    f1_kurtosis = compute_kurtosis(f_n)\n",
    "    f1_min_max = compute_min_max(f_n)\n",
    "    f1_sma = compute_signal_magnitude_area(f_n)\n",
    "    f1_zcr = compute_zero_crossing_rate(f_n)\n",
    "    f1_sc = compute_spectral_centroid(f_n)\n",
    "    f1_entropy = compute_spectral_entropy(f_n)\n",
    "    f1_energy = compute_spectral_energy(f_n)\n",
    "    f1_pfreq = compute_principle_frequency(f_n)\n",
    "    return f1_mean, f1_var, f1_mad, f1_rms, f1_iqr, f1_per75, f1_kurtosis, f1_min_max, f1_sma, f1_zcr, f1_sc, f1_entropy, f1_energy, f1_pfreq\n",
    "\n",
    "def extract_raw_data_features(X):\n",
    "    new_features = []\n",
    "#     rows = X.shape[0]\n",
    "#     cols = X.shape[1]\n",
    "#     for row in range(rows):\n",
    "#         features = []\n",
    "#         for col in range(cols):\n",
    "#             f_n = np.array(X[row][col])\n",
    "#             feature = extract_raw_data_features_per_row(f_n)\n",
    "#             features.append(feature)\n",
    "#         new_features.append(features)\n",
    "    for col in [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]:\n",
    "        features = []\n",
    "        f_n = np.array(X[col])\n",
    "        feature = extract_raw_data_features_per_row(f_n)\n",
    "#         features.append(feature)\n",
    "        new_features.append(feature)\n",
    "#     new\n",
    "#     return pd.DataFrame(data=np.array(new_features), columns=[\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"] )\n",
    "    return new_features\n",
    "\n",
    "# cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]\n",
    "# final_data = extract_raw_data_features(np.array(pdata[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf4cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featureslist(final_data):\n",
    "#     new_data = []\n",
    "#     for row in range(0,np.array(final_data).shape[0]):\n",
    "#         row_features = []\n",
    "#         for col in range(0,np.array(final_data).shape[1]):\n",
    "#             feature_list = np.array(final_data)[row][col]\n",
    "#             for feature in feature_list:\n",
    "#                 row_features.append(feature)\n",
    "#         new_data.append(row_features)\n",
    "#         print(\"Row: \" + str(row) + \"done\")\n",
    "\n",
    "#     feature_name_list = [\"_mean\", \"_var\", \"_mad\", \"_rms\", \"_iqr\", \"_per75\", \"_kurtosis\", \"_min_max\", \"_sma\", \"_zcr\", \"_sc\", \"_entropy\", \"_energy\", \"_pfreq\"]\n",
    "#     cols = []\n",
    "#     for things in [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]:\n",
    "#         for feature in feature_name_list:\n",
    "#             cols.append(things+feature)\n",
    "\n",
    "#     data = pd.DataFrame(data=np.array(new_data), columns=cols)\n",
    "#     data = data.dropna()\n",
    "    new_data = []\n",
    "    for row in range(np.array(final_data).shape[0]):\n",
    "        for col in range(np.array(final_data).shape[1]):\n",
    "            new_data.append(final_data[row][col])\n",
    "    return new_data\n",
    "#     return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7458d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(data):\n",
    "    combined_raw = []\n",
    "    new_data = []\n",
    "#     new_data = pd.DataFrame(columns=['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    for col in range(6):\n",
    "        for row in range(len(data)):\n",
    "            combined_raw.append(data[row][col])\n",
    "        new_data.append(combined_raw)\n",
    "        combined_raw = []\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27054f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 84) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 84), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 84).\n",
      "1/1 [==============================] - 0s 399ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'grenade'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a function which accepts raw data parameter.\n",
    "#raw data would be a queue the form 600 * ['W',acc_x,acc_y,acc_z,gyr_x,gyr_y,gyr_z]\n",
    "raw_data = []\n",
    "pkt1 = ('W',0.2,0.2,0.3,0.4,0.5,0.6)\n",
    "pkt2 = ('W',0.1,0.1,0.1,1.1,1.2,0.1)\n",
    "pkt3 = ('W',1.1,1.2,1.3,0.1,100000,1.6)\n",
    "raw_data.append(pkt1)\n",
    "raw_data.append(pkt2)\n",
    "raw_data.append(pkt3)\n",
    "\n",
    "def process(raw_data):\n",
    "    data = pd.DataFrame(columns=['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    for i in range(len(raw_data)):\n",
    "        list_row = [raw_data[i][1],raw_data[i][2],raw_data[i][3],raw_data[i][4],raw_data[i][5],raw_data[i][6]]\n",
    "        data.loc[len(data)] = list_row\n",
    "    final_data = combine_rows(data.values.tolist())\n",
    "    final_data = pd.DataFrame(data=np.array(final_data).T, columns = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"])\n",
    "    final_data = extract_raw_data_features(final_data)\n",
    "    final_data = create_featureslist(final_data)\n",
    "#     data = np.array(data)\n",
    "#     return pd.DataFrame(np.array(final_data).T)\n",
    "#     return pd.DataFrame(np.array(final_data))\n",
    "#     return len(np.array(final_data[0]))\n",
    "\n",
    "    model = load_model('./hardware_ai/cg4002/action_detection.h5')\n",
    "#     model.get_weights()\n",
    "    final_data = np.array([final_data])\n",
    "    #generate prediction from model\n",
    "    output = model.predict(final_data).tolist()[0]\n",
    "    prediction = output.index(max(output))\n",
    "\n",
    "    if prediction == 0:\n",
    "        return \"reload\"\n",
    "    if prediction == 1:\n",
    "        return \"shield\"\n",
    "    if prediction == 2:\n",
    "        return \"grenade\"\n",
    "    if prediction == 3:\n",
    "        return \"logout\"\n",
    "    if prediction == 4:\n",
    "        return \"\"\n",
    "#     return prediction\n",
    "    \n",
    "#     return output\n",
    "# def process(raw_data):\n",
    "#     print(\"Hello. I have received the raw data.\" + \"This is the first packed.\" + raw_data[0])\n",
    "#     return 1\n",
    "\n",
    "process(raw_data)      \n",
    "    \n",
    "#return lower case string // if not an action, return none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_file(filepath):\n",
    "  dataframe = pd.read_csv(filepath)\n",
    "  return dataframe\n",
    "\n",
    "data = load_file(\"./hardware_ai/cg4002/data.csv\")\n",
    "data.head()\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.columns[:84]].astype('float64').to_numpy()\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8204e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"prediction\"].to_numpy()\n",
    "x = data[data.columns[1:85]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97698873",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1] * 84)\n",
    "y = np.array([0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39670ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = 0\n",
    "#Setting a threshold for onset detection\n",
    "# THRESHOLD = 0.01\n",
    "# threshold_sum = 0\n",
    "dma = overlay.axi_dma_0        \n",
    "# take in 10 datapoints, average out, compare to threshold\n",
    "in_buffer = allocate(shape=x.shape, dtype=np.double)\n",
    "out_buffer = allocate(shape=(1,), dtype=np.double)\n",
    "print(in_buffer)\n",
    "print(out_buffer)\n",
    "for i in range(x.shape[0]):\n",
    "    overlay = Overlay(\"./hardware_ai/cg4002/design_1_wrapper.bit\")\n",
    "    dma = overlay.axi_dma_0        \n",
    "#     inputs = x[n]\n",
    "#     for i in range(84):\n",
    "    in_buffer[i] = x[i];\n",
    "#         threshold_sum += inputs[i];\n",
    "#         print(threshold_sum)\n",
    "# print(in_buffer)\n",
    "# print(out_buffer)\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "# print(\"aaa1\")\n",
    "# print(in_buffer)\n",
    "# print(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "# print(\"aaa2\")\n",
    "dma.recvchannel.wait()\n",
    "# print(\"aaa3\")\n",
    "\n",
    "out_buffer\n",
    "# if y[i] == np.argmax(out_buffer):\n",
    "#     correct_pred += 1;\n",
    "\n",
    "# accuracy = 100 * correct_pred / len(x)\n",
    "# print('Accuracy: {}'. format(accuracy))\n",
    "# print('Process time: ' + str(time.time() - start) + \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17fbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
