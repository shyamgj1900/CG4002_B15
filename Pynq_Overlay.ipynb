{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c6c21cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import DefaultIP\n",
    "from pynq import allocate\n",
    "from pynq import MMIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler #new\n",
    "from joblib import load\n",
    "\n",
    "import time\n",
    "overlay = Overlay(\"./hardware_ai/cg4002/design_1_wrapper.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a525ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy --upgrade --ignore-installed\n",
    "# !pip install scikit-learn\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0f0fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c4ec43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_IP_BASE_ADDRESS = 0x80000000\n",
    "ADDRESS_RANGE = 0x10000\n",
    "ADDRESS_OFFSET = 0x0\n",
    "\n",
    "mmio = MMIO(NN_IP_BASE_ADDRESS, ADDRESS_RANGE)\n",
    "ap_start = 0x1\n",
    "ap_auto_reset = 0x80\n",
    "mmio.write(ADDRESS_OFFSET, ap_start|ap_auto_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06cccac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "def compute_variance(data):\n",
    "    return np.var(data)\n",
    "\n",
    "def compute_median_absolute_deviation(data):\n",
    "    return stats.median_absolute_deviation(data)\n",
    "\n",
    "def compute_root_mean_square(data):\n",
    "    def compose(*fs):\n",
    "        def wrapped(x):\n",
    "            for f in fs[::-1]:\n",
    "                x = f(x)\n",
    "            return x\n",
    "        return wrapped\n",
    "    rms = compose(np.sqrt, np.mean, np.square)\n",
    "    return rms(data)\n",
    "\n",
    "def compute_interquartile_range(data):\n",
    "    return stats.iqr(data)\n",
    "\n",
    "def compute_percentile_75(data):\n",
    "    return np.percentile(data, 75)\n",
    "\n",
    "def compute_kurtosis(data):\n",
    "    return stats.kurtosis(data)\n",
    "\n",
    "def compute_min_max(data):\n",
    "    return np.max(data) - np.min(data)\n",
    "\n",
    "def compute_signal_magnitude_area(data):\n",
    "    return np.sum(data) / len(data)\n",
    "\n",
    "def compute_zero_crossing_rate(data):\n",
    "    return ((data[:-1] * data[1:]) < 0).sum()\n",
    "\n",
    "def compute_spectral_centroid(data):\n",
    "    spectrum = np.abs(np.fft.rfft(data))\n",
    "    normalized_spectrum = spectrum / np.sum(spectrum)  \n",
    "    normalized_frequencies = np.linspace(0, 1, len(spectrum))\n",
    "    spectral_centroid = np.sum(normalized_frequencies * normalized_spectrum)\n",
    "    return spectral_centroid\n",
    "\n",
    "def compute_spectral_entropy(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return stats.entropy(power_density)\n",
    "\n",
    "def compute_spectral_energy(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return np.sum(np.square(power_density))\n",
    "\n",
    "def compute_principle_frequency(data):\n",
    "    freqs, power_density = signal.welch(data)\n",
    "    return freqs[np.argmax(np.square(power_density))]\n",
    "\n",
    "def extract_raw_data_features_per_row(f_n):\n",
    "    f1_mean = compute_mean(f_n)\n",
    "    f1_var = compute_variance(f_n)\n",
    "    f1_mad = compute_median_absolute_deviation(f_n)\n",
    "    f1_rms = compute_root_mean_square(f_n)\n",
    "    f1_iqr = compute_interquartile_range(f_n)\n",
    "    f1_per75 = compute_percentile_75(f_n)\n",
    "    f1_kurtosis = compute_kurtosis(f_n)\n",
    "    f1_min_max = compute_min_max(f_n)\n",
    "    f1_sma = compute_signal_magnitude_area(f_n)\n",
    "    f1_zcr = compute_zero_crossing_rate(f_n)\n",
    "    f1_sc = compute_spectral_centroid(f_n)\n",
    "    f1_entropy = compute_spectral_entropy(f_n)\n",
    "    f1_energy = compute_spectral_energy(f_n)\n",
    "    f1_pfreq = compute_principle_frequency(f_n)\n",
    "    return f1_mean, f1_var, f1_mad, f1_rms, f1_iqr, f1_per75, f1_kurtosis, f1_min_max, f1_sma, f1_zcr, f1_sc, f1_entropy, f1_energy, f1_pfreq\n",
    "\n",
    "def extract_raw_data_features(X):\n",
    "    new_features = []\n",
    "#     rows = X.shape[0]\n",
    "#     cols = X.shape[1]\n",
    "#     for row in range(rows):\n",
    "#         features = []\n",
    "#         for col in range(cols):\n",
    "#             f_n = np.array(X[row][col])\n",
    "#             feature = extract_raw_data_features_per_row(f_n)\n",
    "#             features.append(feature)\n",
    "#         new_features.append(features)\n",
    "    for col in [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]:\n",
    "        features = []\n",
    "        f_n = np.array(X[col])\n",
    "        feature = extract_raw_data_features_per_row(f_n)\n",
    "#         features.append(feature)\n",
    "        new_features.append(feature)\n",
    "#     new\n",
    "#     return pd.DataFrame(data=np.array(new_features), columns=[\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"] )\n",
    "    return new_features\n",
    "\n",
    "# cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]\n",
    "# final_data = extract_raw_data_features(np.array(pdata[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbf4cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featureslist(final_data):\n",
    "#     new_data = []\n",
    "#     for row in range(0,np.array(final_data).shape[0]):\n",
    "#         row_features = []\n",
    "#         for col in range(0,np.array(final_data).shape[1]):\n",
    "#             feature_list = np.array(final_data)[row][col]\n",
    "#             for feature in feature_list:\n",
    "#                 row_features.append(feature)\n",
    "#         new_data.append(row_features)\n",
    "#         print(\"Row: \" + str(row) + \"done\")\n",
    "\n",
    "#     feature_name_list = [\"_mean\", \"_var\", \"_mad\", \"_rms\", \"_iqr\", \"_per75\", \"_kurtosis\", \"_min_max\", \"_sma\", \"_zcr\", \"_sc\", \"_entropy\", \"_energy\", \"_pfreq\"]\n",
    "#     cols = []\n",
    "#     for things in [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]:\n",
    "#         for feature in feature_name_list:\n",
    "#             cols.append(things+feature)\n",
    "\n",
    "#     data = pd.DataFrame(data=np.array(new_data), columns=cols)\n",
    "#     data = data.dropna()\n",
    "    new_data = []\n",
    "    for row in range(np.array(final_data).shape[0]):\n",
    "        for col in range(np.array(final_data).shape[1]):\n",
    "            new_data.append(final_data[row][col])\n",
    "    return new_data\n",
    "#     return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7458d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(data):\n",
    "    combined_raw = []\n",
    "    new_data = []\n",
    "#     new_data = pd.DataFrame(columns=['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    for col in range(6):\n",
    "        for row in range(len(data)):\n",
    "            combined_raw.append(data[row][col])\n",
    "        new_data.append(combined_raw)\n",
    "        combined_raw = []\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3dd3f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "27054f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/signal/spectral.py:1967: UserWarning: nperseg = 256 is greater than input length  = 10, using nperseg = 10\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n",
      "/usr/local/share/pynq-venv/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-77.644, 0.7146439999999978, 0.6078660000000055, 77.64860191915885, 1.2750000000000057, -76.9825, -0.7880131133299799, 2.6199999999999903, -77.644, 0.0, 0.008772247276505881, 1.5754229799853303, 2.625485902055415, 0.30000000000000004, -4.354, 0.5409239999999998, 0.5114970000000006, 4.41568114790912, 0.7375000000000003, -3.8024999999999998, 1.0566189179612984, 2.4699999999999998, -4.354, 0.0, 0.10516228726399005, 1.0655058176266776, 2.519575499848079, 0.1, -50.010999999999996, 1.4129089999999995, 1.8384239999999976, 50.025123987852346, 2.355000000000004, -48.832499999999996, -1.685851221190259, 3.0799999999999983, -50.010999999999996, 0.0, 0.00929485540636791, 0.8465391852224279, 75.31602533337313, 0.1, 161.6, 21041.239999999998, 153.4491, 217.15386250306486, 185.0, 246.75, -0.5069505694633762, 475.0, 161.6, 3.0, 0.3781375466327289, 1.23514136871379, 2763000215.1479387, 0.1, -166.2, 80362.96, 306.8982, 328.61132055971535, 347.25, 9.5, -0.2133283357660769, 1054.0, -166.2, 3.0, 0.37426812795538433, 1.1411692867846193, 126314694193.77676, 0.1, 5131.7, 5805.81, 94.1451, 5132.2656497886, 115.5, 5184.25, -0.7890300019623058, 256.0, 5131.7, 0.0, 0.009218532996545915, 1.1804783571626258, 1244715831.2449722, 0.30000000000000004]]\n",
      "[[-0.4124134098750847, -0.7437710061070341, -0.8171211145745064, -0.5999227974014715, -0.8059733394410931, -0.5751722156545669, -0.17836140572947806, -1.1323083900485345, -0.4124134098750847, -0.9465547676302994, -1.0208375045727052, 1.7062146332230785, -0.3745038169801074, 2.1783138651491116, -0.8773942050321721, -0.8427313238931695, -0.9053798188451375, -1.1278110301827475, -0.898870636351032, -0.9946417042948087, 1.025233110997696, -1.0952473928716777, -0.8773942050321721, -1.2350247329880624, -0.7832499326028516, 0.011851706075901334, -0.4042266286486832, -0.299636057227455, -0.6442160134168905, -0.8332170660846606, -0.8275521983819123, -0.7699419604216359, -0.9842301074214843, -0.706621759595175, -1.0744935790603272, -1.0858795694736099, -0.6442160134168905, -0.7227528055289659, -1.1503167845351774, -0.8424965485982283, -0.40302509771289924, -0.41667522763616505, 0.30829970621317304, -0.9868742526656515, -1.0605632678610204, -1.423473561418566, -1.1443555079964671, -1.0565743792895077, -0.1874463103148173, -1.465989354914124, 0.30829970621317304, 0.34289186587316467, -0.38991711654884237, -0.003128257283546639, -0.4386224903364145, -0.6425886829193239, -0.3516926983616987, -0.843139989627496, -1.0077224927687756, -1.2144083559355392, -1.0445366936940026, -1.0162544928257198, 0.10997399758821486, -1.2307440329078279, -0.3516926983616987, 0.3369287987655021, -0.6631746378926033, -0.5045509513929177, -0.39039941944402834, -0.633797732431535, 1.3887399092564947, -0.8070799858757689, -0.9574577017106948, -0.4472433795938234, -0.9713458678585348, 0.20161324392222765, -0.8120900984513397, -1.3786895104180605, 1.3887399092564947, -1.5110183613543144, -1.882429214123701, -0.4854609925161883, -0.38510784258189906, 1.189528264014433]]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 84) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 84), dtype=tf.float32, name='dense_49_input'), name='dense_49_input', description=\"created by layer 'dense_49_input'\"), but it was called on an input with incompatible shape (None, 84).\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "[0.029603438451886177, 3.6087051125122116e-09, 1.770064272932359e-08, 4.7115431556221665e-09, 0.9703965187072754]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a function which accepts raw data parameter.\n",
    "#raw data would be a queue the form 600 * ['W',acc_x,acc_y,acc_z,gyr_x,gyr_y,gyr_z]\n",
    "# raw_data = []\n",
    "# pkt1 = ('W',0.2,0.2,0.3,0.4,0.5,0.6)\n",
    "# pkt2 = ('W',0.1,0.1,0.1,1.1,1.2,0.1)\n",
    "# pkt3 = ('W',1.1,1.2,1.3,0.1,100000,1.6)\n",
    "# raw_data.append(pkt1)\n",
    "# raw_data.append(pkt2)\n",
    "# raw_data.append(pkt3)\n",
    "raw_data = [['W', -79.35, -3.76, -51.5, -8.0, -354.0, 5161.0],\n",
    " ['W', -78.67, -3.98, -51.26, 465.0, -164.0, 5026.0],\n",
    " ['W', -77.06, -4.48, -51.55, -10.0, 60.0, 5065.0],\n",
    " ['W', -76.73, -4.56, -50.97, 83.0, 74.0, 5282.0],\n",
    " ['W', -76.97, -4.15, -50.37, 175.0, -182.0, 5146.0],\n",
    " ['W', -77.92, -3.71, -49.08, 204.0, -289.0, 5080.0],\n",
    " ['W', -77.02, -3.73, -48.65, 315.0, -451.0, 5207.0],\n",
    " ['W', -77.42, -3.93, -48.47, 261.0, -634.0, 5192.0],\n",
    " ['W', -78.37, -5.06, -48.75, 73.0, -142.0, 5054.0],\n",
    " ['W', -76.93, -6.18, -49.51, 58.0, 420.0, 5104.0]]\n",
    "\n",
    "def process(raw_data):\n",
    "    data = pd.DataFrame(columns=['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'])\n",
    "    for i in range(len(raw_data)):\n",
    "        list_row = [raw_data[i][1],raw_data[i][2],raw_data[i][3],raw_data[i][4],raw_data[i][5],raw_data[i][6]]\n",
    "        data.loc[len(data)] = list_row\n",
    "    final_data = combine_rows(data.values.tolist())\n",
    "    final_data = pd.DataFrame(data=np.array(final_data).T, columns = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"])\n",
    "    final_data = extract_raw_data_features(final_data)\n",
    "    final_data = np.array([create_featureslist(final_data)])\n",
    "#     final_data = np.swapaxes(final_data, 0, 1)\n",
    "#     final_data = list(map(lambda x: x[0], final_data))\n",
    "#     print(len(final_data[0]))\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(np.array(final_data).reshape(1, -1).tolist())\n",
    "#     final_data = scaler.transform(np.array(final_data).reshape(1, -1))\n",
    "#     print(final_data)\n",
    "#     final_data = pd.DataFrame(final_data)\n",
    "#     final_data = final_data[final_data.columns[:84]].astype('float64').to_numpy()\n",
    "    print(final_data.tolist())\n",
    "    scaler=load('./hardware_ai/cg4002/scaler.joblib')\n",
    "#     print(scaler)\n",
    "#     scaler = StandardScaler()\n",
    "    final_data = scaler.transform(final_data.tolist())\n",
    "    print(final_data.tolist())\n",
    "\n",
    "#     final_data = scaler.transform(final_data.tolist())\n",
    "#     print(final_data.tolist())\n",
    "\n",
    "    model = load_model('./hardware_ai/cg4002/detection.h5')\n",
    "#     model.get_weights()\n",
    "#     final_data = np.array([final_data])\n",
    "    #generate prediction from model\n",
    "    output = model.predict(final_data).tolist()[0]\n",
    "    print(output)\n",
    "    prediction = output.index(max(output))\n",
    "\n",
    "    if prediction == 0:\n",
    "        return \"reload\"\n",
    "    if prediction == 1:\n",
    "        return \"shield\"\n",
    "    if prediction == 2:\n",
    "        return \"grenade\"\n",
    "    if prediction == 3:\n",
    "        return \"logout\"\n",
    "    if prediction == 4:\n",
    "        return \"\"\n",
    "#     return prediction\n",
    "    \n",
    "#     return output\n",
    "# def process(raw_data):\n",
    "#     print(\"Hello. I have received the raw data.\" + \"This is the first packed.\" + raw_data[0])\n",
    "#     return 1\n",
    "\n",
    "process(raw_data)      \n",
    "    \n",
    "#return lower case string // if not an action, return none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_file(filepath):\n",
    "  dataframe = pd.read_csv(filepath)\n",
    "  return dataframe\n",
    "\n",
    "data = load_file(\"./hardware_ai/cg4002/data.csv\")\n",
    "data.head()\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.columns[:84]].astype('float64').to_numpy()\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8204e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"prediction\"].to_numpy()\n",
    "x = data[data.columns[1:85]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97698873",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1] * 84)\n",
    "y = np.array([0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39670ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = 0\n",
    "#Setting a threshold for onset detection\n",
    "# THRESHOLD = 0.01\n",
    "# threshold_sum = 0\n",
    "dma = overlay.axi_dma_0        \n",
    "# take in 10 datapoints, average out, compare to threshold\n",
    "in_buffer = allocate(shape=x.shape, dtype=np.double)\n",
    "out_buffer = allocate(shape=(1,), dtype=np.double)\n",
    "print(in_buffer)\n",
    "print(out_buffer)\n",
    "for i in range(x.shape[0]):\n",
    "    overlay = Overlay(\"./hardware_ai/cg4002/design_1_wrapper.bit\")\n",
    "    dma = overlay.axi_dma_0        \n",
    "#     inputs = x[n]\n",
    "#     for i in range(84):\n",
    "    in_buffer[i] = x[i];\n",
    "#         threshold_sum += inputs[i];\n",
    "#         print(threshold_sum)\n",
    "# print(in_buffer)\n",
    "# print(out_buffer)\n",
    "dma.sendchannel.transfer(in_buffer)\n",
    "dma.recvchannel.transfer(out_buffer)\n",
    "# print(\"aaa1\")\n",
    "# print(in_buffer)\n",
    "# print(out_buffer)\n",
    "dma.sendchannel.wait()\n",
    "# print(\"aaa2\")\n",
    "dma.recvchannel.wait()\n",
    "# print(\"aaa3\")\n",
    "\n",
    "out_buffer\n",
    "# if y[i] == np.argmax(out_buffer):\n",
    "#     correct_pred += 1;\n",
    "\n",
    "# accuracy = 100 * correct_pred / len(x)\n",
    "# print('Accuracy: {}'. format(accuracy))\n",
    "# print('Process time: ' + str(time.time() - start) + \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17fbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
